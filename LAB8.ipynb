{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dSZMO4vKQGwU"
   },
   "source": [
    "# Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2SHyslFjQGwV"
   },
   "source": [
    "-- * based on the Python Course for the Humanities by Folgert Karsdorp and Maarten van Gompel*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-BkP0d2RQGwX"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NFCNZ2aKQGwY"
   },
   "source": [
    "In this session we will focus on one of the most important tasks in Humanities research: text processing. One of the goals of text processing is to clean up your data as a pre-step to some kind of data analysis. Another common goal is to convert a given text collection to a different format. In this session we will provide you with the necessary tools to work with collections of texts, clean them and perform some rudimentary data analyses on them.\n",
    "\n",
    "In this notebook, you will look at opening a text file, reading the text, and counting some word occurences. The examples shown will introduce a few new Python concepts. These include reading from a file, loops, functions and dictionaries. \n",
    "\n",
    "As before, read the explanations in the cells, and execute the cells containing code to see how it works. There are also 5 exercises in this notebook which you have to do yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g20z0f0sQGwY"
   },
   "source": [
    "## Reading files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WYrNWJfaQGwZ"
   },
   "source": [
    "The material for this course contained a small text file called \"austen-emma-excerpt.txt\". This should be saved in the same directory where you saved the notebook. Put it in a sub-directory called \"data\". Then use the function 'open' to open the \"austen-emma-excerpt.txt\": \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w-LPh2aUQGwa"
   },
   "outputs": [],
   "source": [
    "infile = open('data/austen-emma-excerpt.txt') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lTHpOSHwQGwe"
   },
   "source": [
    "We now print `infile`. What do you think that will happen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xesy472uQGwf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='data/austen-emma-excerpt.txt' mode='r' encoding='cp1252'>\n"
     ]
    }
   ],
   "source": [
    "print(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o2i2Yc0OQGwh"
   },
   "source": [
    "\"Hey! That's not what I expected to happen!\", you might think. Python is not printing the contents of the file but only some mysterious mention of some `TextIOWrapper`. This `TextIOWrapper` thing is Python's way of saying it has *opened* a connection to the file `data/austen-emma-excerpt.txt`. In order to *read* the contents of the file we must add the function `read` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "77eQiQHeQGwi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emma by Jane Austen 1816\n",
      "\n",
      "VOLUME I\n",
      "\n",
      "CHAPTER I\n",
      "\n",
      "\n",
      "Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n",
      "and happy disposition, seemed to unite some of the best blessings\n",
      "of existence; and had lived nearly twenty-one years in the world\n",
      "with very little to distress or vex her.\n",
      "\n",
      "She was the youngest of the two daughters of a most affectionate,\n",
      "indulgent father; and had, in consequence of her sister's marriage,\n",
      "been mistress of his house from a very early period.  Her mother\n",
      "had died too long ago for her to have more than an indistinct\n",
      "remembrance of her caresses; and her place had been supplied\n",
      "by an excellent woman as governess, who had fallen little short\n",
      "of a mother in affection.\n"
     ]
    }
   ],
   "source": [
    "print(infile.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XZwnSPE0QGwl"
   },
   "source": [
    "`read` is a function that operates on `TextWrapper` objects and allows us to read the contents of a file into Python. Let's assign the contents of the file to the variable `text`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GTj3ofAhQGwl"
   },
   "outputs": [],
   "source": [
    "infile = open('data/austen-emma-excerpt.txt')\n",
    "text = infile.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-P8trjVbQGwp"
   },
   "source": [
    "The variable `text` now holds the contents of the file `data/austen-emma-excerpt.txt` and we can access and manipulate it just like any other string. After we read the contents of a file, the `TextWrapper` no longer needs to be open. In fact, it is good practice to close it as soon as you do not need it anymore. Now, lo and behold, we can achieve that with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PkIqATliQGwp"
   },
   "outputs": [],
   "source": [
    "infile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iHzPHOfTQGws"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WZ2bNx9nQGwy"
   },
   "source": [
    "## Writing our first function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sZFzWiRmQGwz"
   },
   "source": [
    "Remember that in a previous lab, we counted the number of hashtags in Tweets? Counting objects in a text is a very common thing to do, and Python contains the function `count` especially for this purpose. The function operates on strings (`somestring.count(argument)`) and takes as argument the object you want to count. Using this function, we can easily count the number of \"e\"s in our text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6nFi73uQGw0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    }
   ],
   "source": [
    "number_of_es = text.count(\"e\")\n",
    "print(number_of_es)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "huSQ1sWMQGw2"
   },
   "source": [
    "In fact, `count` takes as argument any string you would like to find. We could just as well count how often the determiner `an` occurs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "loHiqg2xQGw3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print(text.count(\"an\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zrVe9KihQGw9"
   },
   "source": [
    "The string `an` is found 12 times in our text. Does that mean that the word *an* occurs 12 times in our text? Go ahead. Count it yourself. In fact, *an* occurs only twice... Think about this. Why does Python print 12?\n",
    "\n",
    "If we want to count how often the word *an* occurs in the text and not the string `an`, we could surround *an* with spaces, like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mKQj2RGuQGw-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(text.count(\" an \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fjx60b_pQGxB"
   },
   "source": [
    "Although it gets the job done in this particular case, it is generally not a very solid way of counting words in a text. What if there are instances of *an* followed by a semicolon or some end-of-sentence marker? Then we would need to query the text multiple times for each possible context of *an*. For that reason, we're going to approach the problem using a different, more sophisticated strategy. \n",
    "\n",
    "Recall from the previous chapter the function `split`. What does this function do? The function `split` operates on a string and splits a string on spaces and returns a list of smaller strings (or words):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mtyu_ZplQGxC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Emma', 'by', 'Jane', 'Austen', '1816', 'VOLUME', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse,', 'handsome,', 'clever,', 'and', 'rich,', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition,', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', 'of', 'existence;', 'and', 'had', 'lived', 'nearly', 'twenty-one', 'years', 'in', 'the', 'world', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'her.', 'She', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate,', 'indulgent', 'father;', 'and', 'had,', 'in', 'consequence', 'of', 'her', \"sister's\", 'marriage,', 'been', 'mistress', 'of', 'his', 'house', 'from', 'a', 'very', 'early', 'period.', 'Her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of', 'her', 'caresses;', 'and', 'her', 'place', 'had', 'been', 'supplied', 'by', 'an', 'excellent', 'woman', 'as', 'governess,', 'who', 'had', 'fallen', 'little', 'short', 'of', 'a', 'mother', 'in', 'affection.']\n"
     ]
    }
   ],
   "source": [
    "print(text.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s8oYGofwQGxD"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TqhpfwpNQGxF"
   },
   "source": [
    "#### Counting words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V7wQ5RYYQGxG"
   },
   "source": [
    "The next cell shows you an example of how to count how often certain words occur in a list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U3y1gmgDQGxH"
   },
   "outputs": [],
   "source": [
    "words = text.split()\n",
    "number_of_hits = 0\n",
    "item_to_count = \"in\"\n",
    "for word in words:\n",
    "    if word == item_to_count:\n",
    "        number_of_hits += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "91mQSLuHQGxK"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IOeWnoN2QGxK"
   },
   "source": [
    "We will go through the code step by step. We would like to know how often the preposition *in* occurs in our text. As a first step we will split the string `text` into a list of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GIl7jyZUQGxL"
   },
   "outputs": [],
   "source": [
    "words = text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QMRgFL-RQGxN"
   },
   "source": [
    "Next we define a variable `number_of_hits` and set it to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X_T2f0usQGxP"
   },
   "outputs": [],
   "source": [
    "number_of_hits = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0D31VMXtQGxQ"
   },
   "source": [
    "The final step is to loop over all words in `words` and add 1 to `number_of_ins` if we find a word that is equal to `in`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uJHOa4_DQGxR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "item_to_count = \"in\"\n",
    "for word in words:\n",
    "    if word == item_to_count:\n",
    "        number_of_hits += 1\n",
    "print(number_of_hits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6RM3CXsNQGxU"
   },
   "source": [
    "Now, say we would like to know how often the word *of* occurs in our text. We could adapt the previous lines of code to search for the word *of*, but what if we also would like to count the number of times *the* occurs, and *house* and *had* and... It would be really cumbersome to repeat all these lines of code for each particular search term we have. Programming is supposed to reduce our workload, not increase it. Just like the function `count` for strings, we would like to have a function that operates on lists, takes as argument the object we would like to count and returns the number of times this object occurs in our list.\n",
    "\n",
    "In this and the previous chapter you have already seen lots of functions. A function does something, often based on some argument you pass to it, and generally returns a result. You are not just limited to using functions in the standard library but you can write your own functions.\n",
    "\n",
    "In fact, you *must* write your own functions. Separating your problem into sub-problems and writing a function for each of those is an immensely important part of well-structured programming. Functions are defined using the `def` keyword, they take a name and optionally a number of parameters. \n",
    "\n",
    "    def some_name(optional_parameters):\n",
    "\n",
    "The `return` statement returns a value back to the caller and always ends the execution of the function. \n",
    "\n",
    "Going back to our problem, we want to write a function called `count_in_list`. It takes two arguments: (1) the object we would like to count and (2) the list in which we want to count that object. Let's write down the function definition in Python:\n",
    "\n",
    "    def count_in_list(item_to_count, list_to_search):\n",
    "    \n",
    "Do you understand all the syntax and keywords in the definition above? Now all we need to do is to add the lines of code we wrote before to the body of this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DbtSRZuoQGxU"
   },
   "outputs": [],
   "source": [
    "def count_in_list(item_to_count, list_to_search): \n",
    "    number_of_hits = 0                            \n",
    "    for item in list_to_search:                   \n",
    "        if item == item_to_count:                 \n",
    "            number_of_hits += 1                   \n",
    "    return number_of_hits                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4bHl04yDQGxX"
   },
   "source": [
    "All code should be familiar to you, except the `return` keyword. The `return` keyword is there to tell python to return as a result of calling the function the argument `number_of_hits`. OK, let's go through our function one more time, just to make sure you really understand all of it.\n",
    "\n",
    "1. First we define a function using `def` and give it the name `count_in_list` (line 1);\n",
    "2. This function takes two arguments: `item_to_count` and `list_to_search` (line 1);\n",
    "3. Within the function, we define a variable `number_of_hits` and assign to it the value zero (since at that stage we haven't found anything yet (line 2));\n",
    "4. We loop over all words in `list_to_search` (line 3);\n",
    "5. If we find a word that is equal to `item_to_count` (line 4), we add 1 to `number_of_hits` (line 5);\n",
    "6. Return the result of `number_of_hits` (line 6).\n",
    "\n",
    "Let's test our little function! We will first count how often the word *an* occurs in our list of words `words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1uVL-XZ_QGxX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(count_in_list(\"an\", words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8qYXgEpkQGxY"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yGPdpWNKQGxa"
   },
   "source": [
    "#### Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tqQqUP_QQGxa"
   },
   "source": [
    "Using the function we defined, print how often the word *the* occurs in our text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xt8WuwaeQGxb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# insert your code here\n",
    "print(count_in_list(\"the\",words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S8arHe-XQGxd"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1sbkG1vsQGxd"
   },
   "source": [
    "## A more general count function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LPrn_H48QGxf"
   },
   "source": [
    "Our function `count_in_list` is a concise and convenient piece of code allowing us to rapidly and without too much repitition count how often certain items occur in a given list. Now what if we would like to find out for all words in our text how often they occur. Then it would be still quite cumbersome to call our function for each unique word. We would like to have a function that takes as argument a particular list and counts for each unique item in that list how often it occurs. There are multiple ways of writing such a function. We will show you two ways of doing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-zBS_KCVQGxg"
   },
   "source": [
    "### A count function (take 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8-_NFSJ_QGxg"
   },
   "source": [
    "In the previous chapter you have acquainted yourself with the `dictionary` structure. Recall that a dictionary consists of keys and values and allows you to quickly lookup a value. We will use a dictionary to write the function `counter` that takes as argument a list and returns a `dictionary` with `keys` for each unique item and `values` showing the number of times it occurs in the list. We will first write some code without the function declaration. If that works, we will add it, just as before, to the body of a function.\n",
    "\n",
    "We start with defining a variable `counts` which is an empty dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b9-fP8hpQGxi"
   },
   "outputs": [],
   "source": [
    "counts = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KLdurt3mQGxj"
   },
   "source": [
    "Next we will loop over all words in our list `words`. For each word, we check whether the dictionary already contains it. If so, we add 1 to its value. If not, we add the word to the dictionary and assign to it the value 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_imIGWruQGxk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Emma': 2, 'by': 2, 'Jane': 1, 'Austen': 1, '1816': 1, 'VOLUME': 1, 'I': 2, 'CHAPTER': 1, 'Woodhouse,': 1, 'handsome,': 1, 'clever,': 1, 'and': 5, 'rich,': 1, 'with': 2, 'a': 4, 'comfortable': 1, 'home': 1, 'happy': 1, 'disposition,': 1, 'seemed': 1, 'to': 3, 'unite': 1, 'some': 1, 'of': 8, 'the': 4, 'best': 1, 'blessings': 1, 'existence;': 1, 'had': 4, 'lived': 1, 'nearly': 1, 'twenty-one': 1, 'years': 1, 'in': 3, 'world': 1, 'very': 2, 'little': 2, 'distress': 1, 'or': 1, 'vex': 1, 'her.': 1, 'She': 1, 'was': 1, 'youngest': 1, 'two': 1, 'daughters': 1, 'most': 1, 'affectionate,': 1, 'indulgent': 1, 'father;': 1, 'had,': 1, 'consequence': 1, 'her': 4, \"sister's\": 1, 'marriage,': 1, 'been': 2, 'mistress': 1, 'his': 1, 'house': 1, 'from': 1, 'early': 1, 'period.': 1, 'Her': 1, 'mother': 2, 'died': 1, 'too': 1, 'long': 1, 'ago': 1, 'for': 1, 'have': 1, 'more': 1, 'than': 1, 'an': 2, 'indistinct': 1, 'remembrance': 1, 'caresses;': 1, 'place': 1, 'supplied': 1, 'excellent': 1, 'woman': 1, 'as': 1, 'governess,': 1, 'who': 1, 'fallen': 1, 'short': 1, 'affection.': 1}\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    if word in counts:\n",
    "        counts[word] = counts[word] + 1\n",
    "    else:\n",
    "        counts[word] = 1\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "omZ-dlE2QGxo"
   },
   "source": [
    "If you don't remember anymore how dictionaries work, go back to the previous chapter and read the part about dictionaries once more.\n",
    "\n",
    "Now that our code is working, we can add it to a function. We define the function `counter` using the `def` keyword. It takes one argument (`list_to_search`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YxfL3rlnQGxo"
   },
   "outputs": [],
   "source": [
    "def counter(list_to_search):                 \n",
    "    counts = {}                              \n",
    "    for word in list_to_search:              \n",
    "        if word in counts:                   \n",
    "            counts[word] = counts[word] + 1  \n",
    "        else:                                \n",
    "            counts[word] = 1                 \n",
    "    return counts                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H_L-7L2_QGxq"
   },
   "source": [
    "Hopefully we are boring you, but let's go through this function step by step.\n",
    "\n",
    "1. We define a function using `def` and give it the name `counter` (line 1);\n",
    "2. This function takes a single argument `list_to_search` which is the list we want to search through (line 1);\n",
    "3. Next we define a variable `counts` which is an empty dictionary (line 2);\n",
    "4. We loop over all words in `list_to_search` (line 3);\n",
    "5. If the word is already in `counts`, we look up its current value and add 1 to it (line 4-5);\n",
    "6. If the word is not in `counts` (else clause), we add the word to the dictionary and assign it the value 1 (line 6-7);\n",
    "7. Return the result of counts (line 8);\n",
    "\n",
    "Let's try out our new function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lF6Uzv8yQGxq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Emma': 2, 'by': 2, 'Jane': 1, 'Austen': 1, '1816': 1, 'VOLUME': 1, 'I': 2, 'CHAPTER': 1, 'Woodhouse,': 1, 'handsome,': 1, 'clever,': 1, 'and': 5, 'rich,': 1, 'with': 2, 'a': 4, 'comfortable': 1, 'home': 1, 'happy': 1, 'disposition,': 1, 'seemed': 1, 'to': 3, 'unite': 1, 'some': 1, 'of': 8, 'the': 4, 'best': 1, 'blessings': 1, 'existence;': 1, 'had': 4, 'lived': 1, 'nearly': 1, 'twenty-one': 1, 'years': 1, 'in': 3, 'world': 1, 'very': 2, 'little': 2, 'distress': 1, 'or': 1, 'vex': 1, 'her.': 1, 'She': 1, 'was': 1, 'youngest': 1, 'two': 1, 'daughters': 1, 'most': 1, 'affectionate,': 1, 'indulgent': 1, 'father;': 1, 'had,': 1, 'consequence': 1, 'her': 4, \"sister's\": 1, 'marriage,': 1, 'been': 2, 'mistress': 1, 'his': 1, 'house': 1, 'from': 1, 'early': 1, 'period.': 1, 'Her': 1, 'mother': 2, 'died': 1, 'too': 1, 'long': 1, 'ago': 1, 'for': 1, 'have': 1, 'more': 1, 'than': 1, 'an': 2, 'indistinct': 1, 'remembrance': 1, 'caresses;': 1, 'place': 1, 'supplied': 1, 'excellent': 1, 'woman': 1, 'as': 1, 'governess,': 1, 'who': 1, 'fallen': 1, 'short': 1, 'affection.': 1}\n"
     ]
    }
   ],
   "source": [
    "print(counter(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uRjhvmG-QGxt"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X5JWPWNSQGxu"
   },
   "source": [
    "#### Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SKkcFUhIQGxv"
   },
   "source": [
    "Let's put some of the stuff we learnt so far together. What we want you to do is to read into Python the file `data/austen-emma.txt`, convert it to a list of words and assign to the variable `emma_count` how often the word *Emma* occurs in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0HnvqxZ5QGxw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "emma_count = 0\n",
    "# insert you code here\n",
    "infile = open('data/austen-emma.txt')\n",
    "text = infile.read()\n",
    "infile.close()\n",
    "words = text.split()\n",
    "item_to_count = \"Emma\"\n",
    "for word in words:\n",
    "    if word == item_to_count:\n",
    "        emma_count += 1\n",
    "\n",
    "# The following test should print True if your code is correct \n",
    "print(emma_count == 481)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RRUyQq_YQGxx"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UuqaOWz1QGxy"
   },
   "source": [
    "### A count function (take 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PzNIJNAkQGxz"
   },
   "source": [
    "Let's train our function writing skills a little more. We are going to write another counting function, this time using a slightly different strategy. Recall our function `count_in_list`. It takes as argument a list and the item we want to count in that list. It returns the number of times this item occurs in the list. If we call this function for each unique word in `words`, we obtain a list of frequencies, quite similar to the one we get from the function `counter`. What would happen if we just call the function `count_in_list` on each word in `words`? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uBO_tUVbQGxz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emma 2\n",
      "by 2\n",
      "Jane 1\n",
      "Austen 1\n",
      "1816 1\n",
      "VOLUME 1\n",
      "I 2\n",
      "CHAPTER 1\n",
      "I 2\n",
      "Emma 2\n",
      "Woodhouse, 1\n",
      "handsome, 1\n",
      "clever, 1\n",
      "and 5\n",
      "rich, 1\n",
      "with 2\n",
      "a 4\n",
      "comfortable 1\n",
      "home 1\n",
      "and 5\n",
      "happy 1\n",
      "disposition, 1\n",
      "seemed 1\n",
      "to 3\n",
      "unite 1\n",
      "some 1\n",
      "of 8\n",
      "the 4\n",
      "best 1\n",
      "blessings 1\n",
      "of 8\n",
      "existence; 1\n",
      "and 5\n",
      "had 4\n",
      "lived 1\n",
      "nearly 1\n",
      "twenty-one 1\n",
      "years 1\n",
      "in 3\n",
      "the 4\n",
      "world 1\n",
      "with 2\n",
      "very 2\n",
      "little 2\n",
      "to 3\n",
      "distress 1\n",
      "or 1\n",
      "vex 1\n",
      "her. 1\n",
      "She 1\n",
      "was 1\n",
      "the 4\n",
      "youngest 1\n",
      "of 8\n",
      "the 4\n",
      "two 1\n",
      "daughters 1\n",
      "of 8\n",
      "a 4\n",
      "most 1\n",
      "affectionate, 1\n",
      "indulgent 1\n",
      "father; 1\n",
      "and 5\n",
      "had, 1\n",
      "in 3\n",
      "consequence 1\n",
      "of 8\n",
      "her 4\n",
      "sister's 1\n",
      "marriage, 1\n",
      "been 2\n",
      "mistress 1\n",
      "of 8\n",
      "his 1\n",
      "house 1\n",
      "from 1\n",
      "a 4\n",
      "very 2\n",
      "early 1\n",
      "period. 1\n",
      "Her 1\n",
      "mother 2\n",
      "had 4\n",
      "died 1\n",
      "too 1\n",
      "long 1\n",
      "ago 1\n",
      "for 1\n",
      "her 4\n",
      "to 3\n",
      "have 1\n",
      "more 1\n",
      "than 1\n",
      "an 2\n",
      "indistinct 1\n",
      "remembrance 1\n",
      "of 8\n",
      "her 4\n",
      "caresses; 1\n",
      "and 5\n",
      "her 4\n",
      "place 1\n",
      "had 4\n",
      "been 2\n",
      "supplied 1\n",
      "by 2\n",
      "an 2\n",
      "excellent 1\n",
      "woman 1\n",
      "as 1\n",
      "governess, 1\n",
      "who 1\n",
      "had 4\n",
      "fallen 1\n",
      "little 2\n",
      "short 1\n",
      "of 8\n",
      "a 4\n",
      "mother 2\n",
      "in 3\n",
      "affection. 1\n"
     ]
    }
   ],
   "source": [
    "infile = open('data/austen-emma-excerpt.txt')\n",
    "text = infile.read()\n",
    "infile.close()\n",
    "words = text.split()\n",
    "\n",
    "for word in words:\n",
    "    print(word, count_in_list(word, words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TA4PzrI1QGx4"
   },
   "source": [
    "As you can see, we obtain the frequency of each word token in `words`, where we would like to have it only for unique word forms. The challenge is thus to come up with a way to convert our list of words into a structure with solely unique words. For this Python provides a convenient data structure called `set`. It takes as argument some iterable (e.g. a list) and returns a new object containing only unique items:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "efduTUnPQGx4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c', 'b', 'a'}\n"
     ]
    }
   ],
   "source": [
    "x = ['a', 'a', 'b', 'b', 'c', 'c', 'c']\n",
    "unique_x = set(x)\n",
    "print(unique_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Yh34Q9hQGx8"
   },
   "source": [
    "Using `set` we can iterate over all unique words in our word list and print the corresponding frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UequjakEQGx8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very 2\n",
      "by 2\n",
      "vex 1\n",
      "early 1\n",
      "lived 1\n",
      "VOLUME 1\n",
      "CHAPTER 1\n",
      "of 8\n",
      "died 1\n",
      "more 1\n",
      "been 2\n",
      "had, 1\n",
      "affection. 1\n",
      "existence; 1\n",
      "marriage, 1\n",
      "affectionate, 1\n",
      "fallen 1\n",
      "Emma 2\n",
      "house 1\n",
      "his 1\n",
      "world 1\n",
      "I 2\n",
      "who 1\n",
      "place 1\n",
      "long 1\n",
      "a 4\n",
      "indulgent 1\n",
      "the 4\n",
      "period. 1\n",
      "than 1\n",
      "best 1\n",
      "happy 1\n",
      "clever, 1\n",
      "1816 1\n",
      "have 1\n",
      "daughters 1\n",
      "indistinct 1\n",
      "short 1\n",
      "excellent 1\n",
      "her. 1\n",
      "remembrance 1\n",
      "handsome, 1\n",
      "unite 1\n",
      "rich, 1\n",
      "for 1\n",
      "and 5\n",
      "Her 1\n",
      "mother 2\n",
      "Austen 1\n",
      "two 1\n",
      "caresses; 1\n",
      "distress 1\n",
      "governess, 1\n",
      "an 2\n",
      "twenty-one 1\n",
      "too 1\n",
      "mistress 1\n",
      "as 1\n",
      "to 3\n",
      "years 1\n",
      "in 3\n",
      "little 2\n",
      "blessings 1\n",
      "seemed 1\n",
      "father; 1\n",
      "home 1\n",
      "or 1\n",
      "supplied 1\n",
      "She 1\n",
      "Jane 1\n",
      "youngest 1\n",
      "disposition, 1\n",
      "consequence 1\n",
      "her 4\n",
      "some 1\n",
      "woman 1\n",
      "Woodhouse, 1\n",
      "comfortable 1\n",
      "was 1\n",
      "sister's 1\n",
      "ago 1\n",
      "from 1\n",
      "most 1\n",
      "had 4\n",
      "with 2\n",
      "nearly 1\n"
     ]
    }
   ],
   "source": [
    "unique_words = set(words)\n",
    "for word in unique_words:\n",
    "    print(word, count_in_list(word, words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qB0xPtUBQGx_"
   },
   "source": [
    "We wrap the lines of code above into the function `counter2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YU7M9vA5QGyC"
   },
   "outputs": [],
   "source": [
    "def counter2(list_to_search):\n",
    "    unique_words = set(list_to_search)\n",
    "    for word in unique_words:\n",
    "        print(word, count_in_list(word, list_to_search))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LxUZw-y7QGyE"
   },
   "source": [
    "A final check to see whether our function behaves correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pKJZJawwQGyE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very 2\n",
      "by 2\n",
      "vex 1\n",
      "early 1\n",
      "lived 1\n",
      "VOLUME 1\n",
      "CHAPTER 1\n",
      "of 8\n",
      "died 1\n",
      "more 1\n",
      "been 2\n",
      "had, 1\n",
      "affection. 1\n",
      "existence; 1\n",
      "marriage, 1\n",
      "affectionate, 1\n",
      "fallen 1\n",
      "Emma 2\n",
      "house 1\n",
      "his 1\n",
      "world 1\n",
      "I 2\n",
      "who 1\n",
      "place 1\n",
      "long 1\n",
      "a 4\n",
      "indulgent 1\n",
      "the 4\n",
      "period. 1\n",
      "than 1\n",
      "best 1\n",
      "happy 1\n",
      "clever, 1\n",
      "1816 1\n",
      "have 1\n",
      "daughters 1\n",
      "indistinct 1\n",
      "short 1\n",
      "excellent 1\n",
      "her. 1\n",
      "remembrance 1\n",
      "handsome, 1\n",
      "unite 1\n",
      "rich, 1\n",
      "for 1\n",
      "and 5\n",
      "Her 1\n",
      "mother 2\n",
      "Austen 1\n",
      "two 1\n",
      "caresses; 1\n",
      "distress 1\n",
      "governess, 1\n",
      "an 2\n",
      "twenty-one 1\n",
      "too 1\n",
      "mistress 1\n",
      "as 1\n",
      "to 3\n",
      "years 1\n",
      "in 3\n",
      "little 2\n",
      "blessings 1\n",
      "seemed 1\n",
      "father; 1\n",
      "home 1\n",
      "or 1\n",
      "supplied 1\n",
      "She 1\n",
      "Jane 1\n",
      "youngest 1\n",
      "disposition, 1\n",
      "consequence 1\n",
      "her 4\n",
      "some 1\n",
      "woman 1\n",
      "Woodhouse, 1\n",
      "comfortable 1\n",
      "was 1\n",
      "sister's 1\n",
      "ago 1\n",
      "from 1\n",
      "most 1\n",
      "had 4\n",
      "with 2\n",
      "nearly 1\n"
     ]
    }
   ],
   "source": [
    "counter2(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HJmQ5gf9QGyG"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dPHCL9R-QGyJ"
   },
   "source": [
    "## Text clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "avcAgMaQQGyJ"
   },
   "source": [
    "In the previous section we wrote code to compute a frequency distribution of the words in a text stored on our computer. The function `split` is a quick and dirty way of splitting a string into a list of words. However, if we look through the frequency distributions, we notice quite an amount of noise. For instance, the pronoun *her* occurs 4 times, but we also find `her.` occurring 1 time and the capitalized `Her`, also 1 time. Of course we would like to add those counts to that of *her*. As it appears, the tokenization of our text using `split` is fast and simple, but it leaves us with noisy and incorrect frequency distributions. \n",
    "\n",
    "There are essentially two strategies to follow to correct our frequency distributions. The first is to come up with a better procedure of splitting our text into words. The second is to clean-up our text and pass this clean result to the convenient `split` function. For now we will follow the second path.\n",
    "\n",
    "Some words in our text are capitalized. To lowercase these words, Python provides the function `lower`. It operates on strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "APW-OIzEQGyK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n"
     ]
    }
   ],
   "source": [
    "x = 'Emma'\n",
    "x_lower = x.lower()\n",
    "print(x_lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ObwtNXYtQGyM"
   },
   "source": [
    "We can apply this function to our complete text to obtain a completely lowercased text, using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h2lDYLBTQGyM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma by jane austen 1816\n",
      "\n",
      "volume i\n",
      "\n",
      "chapter i\n",
      "\n",
      "\n",
      "emma woodhouse, handsome, clever, and rich, with a comfortable home\n",
      "and happy disposition, seemed to unite some of the best blessings\n",
      "of existence; and had lived nearly twenty-one years in the world\n",
      "with very little to distress or vex her.\n",
      "\n",
      "she was the youngest of the two daughters of a most affectionate,\n",
      "indulgent father; and had, in consequence of her sister's marriage,\n",
      "been mistress of his house from a very early period.  her mother\n",
      "had died too long ago for her to have more than an indistinct\n",
      "remembrance of her caresses; and her place had been supplied\n",
      "by an excellent woman as governess, who had fallen little short\n",
      "of a mother in affection.\n"
     ]
    }
   ],
   "source": [
    "text_lower = text.lower()\n",
    "print(text_lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W40BXmw-QGyO"
   },
   "source": [
    "This solves our problem with miscounting capitalized words, leaving us with the problem of punctuation. The function `replace` is just the function we're looking for. It takes two arguments: (1) the string we would like to replace and (2) the string we want to replace the first argument with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jcqjeu5wQGyO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please remove all dots from this sentence\n"
     ]
    }
   ],
   "source": [
    "x = 'Please. remove. all. dots. from. this. sentence.'\n",
    "x = x.replace(\".\", \"\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4zw6Xw2EQGyQ"
   },
   "source": [
    "Notice that we replace all dots with an empty string written as `\"\"`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OX7JX57uQGyQ"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UbWUsnSFQGyR"
   },
   "source": [
    "#### Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y5Y3v-47QGyR"
   },
   "source": [
    "Write code that to lowercase and remove all commas in the following short text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "emUcS7e3QGyS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "short_text = \"Commas, as it turns out, are so much overestimated.\"\n",
    "# insert your code here\n",
    "short_text = short_text.replace(\",\",\"\")\n",
    "short_text = short_text.lower()\n",
    "\n",
    "# The following test should print True if your code is correct \n",
    "print(short_text == \"commas as it turns out are so much overestimated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lcd4Nyr9QGyU"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5erDQNIEQGyU"
   },
   "source": [
    "We would like to remove all punctuation from a text, not just dots and commas. We will write a function called `remove_punc` that removes all (simple) punctuation from a text. Again, there are many ways in which we can write this function. We will show you two of them. The first strategy is to repeatedly call `replace` on the same string each time replacing a different punctuation character with an empty string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x7Y0XWKOQGyU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commas as it turns out are overestimated Dots however even more so\n"
     ]
    }
   ],
   "source": [
    "def remove_punc(text):\n",
    "    punctuation = '!@#$%^&*()_-+={}[]:;\"\\'|<>,.?/~`'\n",
    "    for marker in punctuation:\n",
    "        text = text.replace(marker, \"\")\n",
    "    return text\n",
    "\n",
    "short_text = \"Commas, as it turns out, are overestimated. Dots, however, even more so!\"\n",
    "print(remove_punc(short_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y5ppKXABQGyX"
   },
   "source": [
    "The second strategy we will follow is to show you that we can achieve the same result without using the built in function `replace`. Remember that a string consists of characters. We can loop over a string accessing each character in turn. Each time we find a punctuation marker we skip to the next character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3KQKeyUSQGyZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commas as it turns out are overestimated Dots however even more so\n"
     ]
    }
   ],
   "source": [
    "def remove_punc2(text):\n",
    "    punctuation = '!@#$%^&*()_-+={}[]:;\"\\'|<>,.?/~`'\n",
    "    clean_text = \"\"\n",
    "    for character in text:\n",
    "        if character not in punctuation:\n",
    "            clean_text += character\n",
    "    return clean_text\n",
    "\n",
    "short_text = \"Commas, as it turns out, are overestimated. Dots, however, even more so!\"\n",
    "print(remove_punc2(short_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fyldy8OfQGya"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g-6NCRSLQGyb"
   },
   "source": [
    "#### Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vs9VRxaEQGyb"
   },
   "source": [
    "1) Can you come up with any pros or cons for each of the two functions above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u-q3Db2lQGyc"
   },
   "source": [
    "Executed two functions the pros is the punctuaions are removed the string printed, and the cons are the uppercase is not changing to lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U7k55cr3QGyc"
   },
   "source": [
    "2) Now it is time to put everything together. We want to write a function `clean_text` that takes as argument a text represented by string. The function should return this string with all punctuation removed and all characters lowercased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "myt1sxpdQGyd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    punctuation = '!@#$%^&*()_-+={}[]:;\"\\'|<>,.?/~`'\n",
    "    remove_punc = \"\"\n",
    "    for character in text:\n",
    "        if character not in punctuation:\n",
    "            remove_punc += character\n",
    "    return remove_punc\n",
    "        \n",
    "\n",
    "short_text = \"Commas, as it turns out, are overestimated. Dots, however, even more so!\"\n",
    "short_text = short_text.lower()\n",
    "print(clean_text(short_text) == \n",
    "      \"commas as it turns out are overestimated dots however even more so\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vnmGigHyQGyf"
   },
   "source": [
    "3) This last excercise puts everything together. We want you to open and read the file `data/austen-emma.txt` text once more, clean up the text and recompute the frequency distribution. Assign to `woodhouse_counts` the number of times the name *Woodhouse* occurs in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vzs8QlbWQGyf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "woodhouse_counts = 0\n",
    "# insert your code here\n",
    "infile = open('data/austen-emma.txt')\n",
    "text = infile.read()\n",
    "infile.close()\n",
    "\n",
    "def remove_punc(text):\n",
    "    punctuation = '!@#$%^&*()_-+={}[]:;\"\\'|<>,.?/~`'\n",
    "    for marker in punctuation:\n",
    "        text = text.replace(marker, \"\")\n",
    "    return text\n",
    "\n",
    "text_lower = text.lower()\n",
    "text1=clean_text(text_lower)\n",
    "def counter2(list_to_search):\n",
    "    unique_words = set(list_to_search)\n",
    "    for word in unique_words:\n",
    "        print(word, count_in_list(word, list_to_search))\n",
    "words=text1.split()\n",
    "item_to_count=\"woodhouse\"\n",
    "for word in words:\n",
    "    if word==item_to_count:\n",
    "        woodhouse_counts+=1\n",
    "\n",
    "# The following test should print True if your code is correct \n",
    "print(woodhouse_counts == 263)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y6xMXLb_QGyh"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dwSIaj7OQGyi"
   },
   "source": [
    "## Writing results to a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qh3mcgqPQGyk"
   },
   "source": [
    "We have accomplished a lot! You have learnt how to read files using Python from your computer, how to manipulate them, clean them up and compute a frequency distribution of the words in a text file. We will finish this chapter with explaining to you how to write your results to a file. We have already seen how to read a text from our disk. Writing to our disk is only slightly different. The following lines of code write a single sentence to the file `first-output.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YVijpdVnQGyk"
   },
   "outputs": [],
   "source": [
    "outfile = open(\"first-output.txt\", mode=\"w\")\n",
    "outfile.write(\"My first output.\")\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Et4qDpnsQGyl"
   },
   "source": [
    "Go ahead and open the file `first-output.txt` located in the folder where this course resides. As you can see it contains the line `My first output.`. To write something to a file we open, just as in the case of reading a file, a `TextIOWrapper` which can be seen as a connection to the file `first-output.txt`. The difference with opening a file for reading is the *mode* with which we open the connection. Here the mode says `w`, meaning \"open the file for writing\". To open a file for reading, we set the mode to `r`. However, since this is Python's default setting, we may omit it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gUMYgv-TQGyl"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hSzhXPVTQGyl"
   },
   "source": [
    "#### Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zw6ycg9vQGym"
   },
   "source": [
    "In the final quiz of this lab we will ask you to write the frequency distribution over the words in `data/austen-emma.txt` to the file `data/austen-frequency-distribution.txt`. We will give you some code to get you started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4nQ1I763QGym"
   },
   "outputs": [],
   "source": [
    "# first open and read data/austen-emma.txt. Don't forget to close the infile\n",
    "infile = open(\"data/austen-emma.txt\")\n",
    "text = infile.read()\n",
    "infile.close()\n",
    "# clean the text\n",
    "def remove_punc(text):\n",
    "    punctuation = '!@#$%^&*()_-+={}[]:;\"\\'|<>,.?/~`'\n",
    "    for marker in punctuation:\n",
    "        text = text.replace(marker, \"\")\n",
    "    return text\n",
    "text_lower=text.lower()\n",
    "\n",
    "# next compute the frequency distribution using the function counter\n",
    "def counter(list_to_search):                 \n",
    "    counts = {}                              \n",
    "    for word in list_to_search:              \n",
    "        if word in counts:                   \n",
    "            counts[word] = counts[word] + 1  \n",
    "        else:                                \n",
    "            counts[word] = 1                 \n",
    "    return counts\n",
    "\n",
    "frequency_distribution = counter(words)\n",
    "\n",
    "# now open the file data/austen-frequency-distribution.txt for writing\n",
    "outfile = open(\"data/austen-frequency-distribution.txt\", mode=\"w\")\n",
    "\n",
    "for word, frequency in frequency_distribution.items():\n",
    "    outfile.write(word + \";\" + str(frequency) + '\\n')\n",
    "    \n",
    "# close the outfile\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QukPSk8qQGyo"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gFwJiu0dQGyo"
   },
   "source": [
    "Ignore the following, it's just here to make the page pretty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lybiU_DYQGyo",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"styles/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jQ-XxN18QGys"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wzodFZJ1QGyt"
   },
   "source": [
    "<p><small><a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a><br /><span xmlns:dct=\"http://purl.org/dc/terms/\" property=\"dct:title\">Python Programming for the Humanities</span> by <a xmlns:cc=\"http://creativecommons.org/ns#\" href=\"http://fbkarsdorp.github.io/python-course\" property=\"cc:attributionName\" rel=\"cc:attributionURL\">http://fbkarsdorp.github.io/python-course</a> is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>. Based on a work at <a xmlns:dct=\"http://purl.org/dc/terms/\" href=\"https://github.com/fbkarsdorp/python-course\" rel=\"dct:source\">https://github.com/fbkarsdorp/python-course</a>.</small></p>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "SITrGFpiQGwt",
    "TqhpfwpNQGxF",
    "yGPdpWNKQGxa",
    "-zBS_KCVQGxg",
    "X5JWPWNSQGxu",
    "UuqaOWz1QGxy",
    "JUtaXOW5QGyH",
    "UbWUsnSFQGyR",
    "g-6NCRSLQGyb",
    "hSzhXPVTQGyl"
   ],
   "name": "Session8.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
